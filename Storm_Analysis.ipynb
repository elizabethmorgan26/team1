{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4817ce44-b747-48d3-9876-812dfa2a3950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helpers import *\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8676994-6bb6-437c-a22c-fa7b68b29d3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202202</td>\n",
       "      <td>20</td>\n",
       "      <td>2118</td>\n",
       "      <td>202202</td>\n",
       "      <td>20</td>\n",
       "      <td>2218</td>\n",
       "      <td>165464</td>\n",
       "      <td>999902</td>\n",
       "      <td>NEVADA</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Strong winds increased ahead of an approaching...</td>\n",
       "      <td>Station (UP994) 3.1 SE West Wendover, Elevatio...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>202202</td>\n",
       "      <td>21</td>\n",
       "      <td>800</td>\n",
       "      <td>202202</td>\n",
       "      <td>22</td>\n",
       "      <td>1000</td>\n",
       "      <td>165465</td>\n",
       "      <td>999903</td>\n",
       "      <td>NEVADA</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A low centered over northern and central Nevad...</td>\n",
       "      <td>Thirteen inches fell at station (BCSN2) Big Cr...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>202202</td>\n",
       "      <td>22</td>\n",
       "      <td>200</td>\n",
       "      <td>202202</td>\n",
       "      <td>22</td>\n",
       "      <td>900</td>\n",
       "      <td>165465</td>\n",
       "      <td>999904</td>\n",
       "      <td>NEVADA</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A low centered over northern and central Nevad...</td>\n",
       "      <td>Fifteen inches fell at station (TJMN2) Toe Jam...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202202</td>\n",
       "      <td>18</td>\n",
       "      <td>1609</td>\n",
       "      <td>202202</td>\n",
       "      <td>18</td>\n",
       "      <td>1609</td>\n",
       "      <td>165611</td>\n",
       "      <td>1001181</td>\n",
       "      <td>ATLANTIC SOUTH</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>PONTE VEDRA</td>\n",
       "      <td>30.050</td>\n",
       "      <td>-81.1700</td>\n",
       "      <td>30.0500</td>\n",
       "      <td>-81.1700</td>\n",
       "      <td>Pre-frontal showers and thunderstorms moved so...</td>\n",
       "      <td>A brief waterspout was observed offshore of So...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>202202</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>202202</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>165668</td>\n",
       "      <td>1001527</td>\n",
       "      <td>AMERICAN SAMOA</td>\n",
       "      <td>97</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>VAITOGI</td>\n",
       "      <td>-14.333</td>\n",
       "      <td>-170.7157</td>\n",
       "      <td>-14.3393</td>\n",
       "      <td>-170.7268</td>\n",
       "      <td>A surface trough over the Islands held  the po...</td>\n",
       "      <td>Over a 24-hour period, WSO Pago Pago recorded ...</td>\n",
       "      <td>CSV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
       "0           202202         20        2118         202202       20      2218   \n",
       "1           202202         21         800         202202       22      1000   \n",
       "2           202202         22         200         202202       22       900   \n",
       "3           202202         18        1609         202202       18      1609   \n",
       "4           202202          2           0         202202        3         0   \n",
       "\n",
       "   EPISODE_ID  EVENT_ID           STATE  STATE_FIPS  ...  END_RANGE  \\\n",
       "0      165464    999902          NEVADA          32  ...        NaN   \n",
       "1      165465    999903          NEVADA          32  ...        NaN   \n",
       "2      165465    999904          NEVADA          32  ...        NaN   \n",
       "3      165611   1001181  ATLANTIC SOUTH          87  ...        7.0   \n",
       "4      165668   1001527  AMERICAN SAMOA          97  ...        5.0   \n",
       "\n",
       "  END_AZIMUTH END_LOCATION BEGIN_LAT  BEGIN_LON  END_LAT   END_LON  \\\n",
       "0         NaN          NaN       NaN        NaN      NaN       NaN   \n",
       "1         NaN          NaN       NaN        NaN      NaN       NaN   \n",
       "2         NaN          NaN       NaN        NaN      NaN       NaN   \n",
       "3          SE  PONTE VEDRA    30.050   -81.1700  30.0500  -81.1700   \n",
       "4         NNW      VAITOGI   -14.333  -170.7157 -14.3393 -170.7268   \n",
       "\n",
       "                                   EPISODE_NARRATIVE  \\\n",
       "0  Strong winds increased ahead of an approaching...   \n",
       "1  A low centered over northern and central Nevad...   \n",
       "2  A low centered over northern and central Nevad...   \n",
       "3  Pre-frontal showers and thunderstorms moved so...   \n",
       "4  A surface trough over the Islands held  the po...   \n",
       "\n",
       "                                     EVENT_NARRATIVE DATA_SOURCE  \n",
       "0  Station (UP994) 3.1 SE West Wendover, Elevatio...         CSV  \n",
       "1  Thirteen inches fell at station (BCSN2) Big Cr...         CSV  \n",
       "2  Fifteen inches fell at station (TJMN2) Toe Jam...         CSV  \n",
       "3  A brief waterspout was observed offshore of So...         CSV  \n",
       "4  Over a 24-hour period, WSO Pago Pago recorded ...         CSV  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging all the datasets into one\n",
    "mergestorm_df = pd.concat( \n",
    "    map(pd.read_csv, [\n",
    "                      \"resources/stormevents_2022.csv\", \n",
    "                      \"resources/stormevents_2021.csv\",\n",
    "                      \"resources/stormevents_2020.csv\",\n",
    "                      \"resources/stormevents_2019.csv\",\n",
    "                      \"resources/stormevents_2018.csv\", \n",
    "                      \"resources/stormevents_2017.csv\", \n",
    "                      \"resources/stormevents_2016.csv\", \n",
    "                      \"resources/stormevents_2015.csv\", \n",
    "                      \"resources/stormevents_2014.csv\", \n",
    "                      \"resources/stormevents_2013.csv\", \n",
    "                      \"resources/stormevents_2012.csv\", \n",
    "                      \"resources/stormevents_2011.csv\", \n",
    "                      \"resources/stormevents_2010.csv\", \n",
    "                      \"resources/stormevents_2009.csv\", \n",
    "                      \"resources/stormevents_2008.csv\"]), ignore_index=True) \n",
    "mergestorm_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d377085a-667c-42e5-91ad-89f3458fb2b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEGIN_YEARMONTH</th>\n",
       "      <th>BEGIN_DAY</th>\n",
       "      <th>BEGIN_TIME</th>\n",
       "      <th>END_YEARMONTH</th>\n",
       "      <th>END_DAY</th>\n",
       "      <th>END_TIME</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>STATE</th>\n",
       "      <th>STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>END_RANGE</th>\n",
       "      <th>END_AZIMUTH</th>\n",
       "      <th>END_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_NARRATIVE</th>\n",
       "      <th>EVENT_NARRATIVE</th>\n",
       "      <th>DATA_SOURCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195004</td>\n",
       "      <td>28</td>\n",
       "      <td>1445</td>\n",
       "      <td>195004</td>\n",
       "      <td>28</td>\n",
       "      <td>1445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10096222</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.12</td>\n",
       "      <td>-99.20</td>\n",
       "      <td>35.17</td>\n",
       "      <td>-99.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195004</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>195004</td>\n",
       "      <td>29</td>\n",
       "      <td>1530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10120412</td>\n",
       "      <td>TEXAS</td>\n",
       "      <td>48</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.90</td>\n",
       "      <td>-98.60</td>\n",
       "      <td>31.73</td>\n",
       "      <td>-98.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104927</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.58</td>\n",
       "      <td>-75.70</td>\n",
       "      <td>40.65</td>\n",
       "      <td>-75.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1830</td>\n",
       "      <td>195007</td>\n",
       "      <td>5</td>\n",
       "      <td>1830</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104928</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.60</td>\n",
       "      <td>-76.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>195007</td>\n",
       "      <td>24</td>\n",
       "      <td>1440</td>\n",
       "      <td>195007</td>\n",
       "      <td>24</td>\n",
       "      <td>1440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104929</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.63</td>\n",
       "      <td>-79.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUB</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   BEGIN_YEARMONTH  BEGIN_DAY  BEGIN_TIME  END_YEARMONTH  END_DAY  END_TIME  \\\n",
       "0           195004         28        1445         195004       28      1445   \n",
       "1           195004         29        1530         195004       29      1530   \n",
       "2           195007          5        1800         195007        5      1800   \n",
       "3           195007          5        1830         195007        5      1830   \n",
       "4           195007         24        1440         195007       24      1440   \n",
       "\n",
       "   EPISODE_ID  EVENT_ID         STATE  STATE_FIPS  ...  END_RANGE END_AZIMUTH  \\\n",
       "0         NaN  10096222      OKLAHOMA          40  ...          0         NaN   \n",
       "1         NaN  10120412         TEXAS          48  ...          0         NaN   \n",
       "2         NaN  10104927  PENNSYLVANIA          42  ...          0         NaN   \n",
       "3         NaN  10104928  PENNSYLVANIA          42  ...          0         NaN   \n",
       "4         NaN  10104929  PENNSYLVANIA          42  ...          0         NaN   \n",
       "\n",
       "  END_LOCATION BEGIN_LAT  BEGIN_LON END_LAT  END_LON EPISODE_NARRATIVE  \\\n",
       "0          NaN     35.12     -99.20   35.17   -99.20               NaN   \n",
       "1          NaN     31.90     -98.60   31.73   -98.60               NaN   \n",
       "2          NaN     40.58     -75.70   40.65   -75.47               NaN   \n",
       "3          NaN     40.60     -76.75     NaN      NaN               NaN   \n",
       "4          NaN     41.63     -79.68     NaN      NaN               NaN   \n",
       "\n",
       "  EVENT_NARRATIVE DATA_SOURCE  \n",
       "0             NaN         PUB  \n",
       "1             NaN         PUB  \n",
       "2             NaN         PUB  \n",
       "3             NaN         PUB  \n",
       "4             NaN         PUB  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merging all the datasets into one for earliest available data years \n",
    "mergestorm1950_1964_df = pd.concat( \n",
    "    map(pd.read_csv, [\"resources/stormevents_1950.csv\", \n",
    "                      \"resources/stormevents_1951.csv\", \n",
    "                      \"resources/stormevents_1952.csv\", \n",
    "                      \"resources/stormevents_1953.csv\", \n",
    "                      \"resources/stormevents_1954.csv\", \n",
    "                      \"resources/stormevents_1955.csv\",\n",
    "                      \"resources/stormevents_1956.csv\", \n",
    "                      \"resources/stormevents_1957.csv\", \n",
    "                      \"resources/stormevents_1958.csv\",\n",
    "                      \"resources/stormevents_1959.csv\", \n",
    "                      \"resources/stormevents_1960.csv\", \n",
    "                      \"resources/stormevents_1961.csv\",\n",
    "                      \"resources/stormevents_1962.csv\", \n",
    "                      \"resources/stormevents_1963.csv\", \n",
    "                      \"resources/stormevents_1964.csv\"]),\n",
    "                      ignore_index=True)\n",
    "mergestorm1950_1964_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7da8d01-e819-4931-a18f-f29a2aad95af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_storm_df(dataFrame, narrow_cols, only_impactful):\n",
    "    narrow_df = dataFrame[narrow_cols] # reduce columns to relevant ones\n",
    "\n",
    "    # translate tornado F scale into simple integer scale\n",
    "    narrow_df['TOR_F_SCALE'] = narrow_df['TOR_F_SCALE'].apply(retype_tornado_scale)\n",
    "\n",
    "    # fill missing values for damage columns\n",
    "    narrow_df[\"DAMAGE_PROPERTY\"] = narrow_df[\"DAMAGE_PROPERTY\"].fillna(\"0.00K\")\n",
    "    narrow_df[\"DAMAGE_CROPS\"] = narrow_df[\"DAMAGE_CROPS\"].fillna(\"0.00K\")\n",
    "\n",
    "    # re-type damage values to float to support math operations\n",
    "    narrow_df['DAMAGE_PROPERTY'] = narrow_df['DAMAGE_PROPERTY'].apply(retype_damage_value)\n",
    "    narrow_df['DAMAGE_CROPS'] = narrow_df['DAMAGE_CROPS'].apply(retype_damage_value)\n",
    "\n",
    "    # merge deaths/injuries/damages columns\n",
    "    narrow_df[\"TOTAL DEATHS\"] = narrow_df[\"DEATHS_DIRECT\"] + narrow_df[\"DEATHS_INDIRECT\"]\n",
    "    narrow_df[\"TOTAL INJURIES\"] = narrow_df[\"INJURIES_DIRECT\"] + narrow_df[\"INJURIES_INDIRECT\"]\n",
    "    narrow_df[\"TOTAL DAMAGES\"] = narrow_df[\"DAMAGE_PROPERTY\"] + narrow_df[\"DAMAGE_CROPS\"]\n",
    "\n",
    "    # remove now extraneous columns; damages columns remain as we perform individual analyses\n",
    "    narrow_df = narrow_df.drop(columns=[\"INJURIES_DIRECT\", \"INJURIES_INDIRECT\",\"DEATHS_DIRECT\", \"DEATHS_INDIRECT\"])\n",
    "\n",
    "    # Narrow down events that have had at least one death and/or at least one injury \n",
    "    if only_impactful:\n",
    "        # still leaves in rows with 0 damages values\n",
    "        narrow_df = narrow_df.loc[(narrow_df[\"TOTAL DEATHS\"] > 0) | (narrow_df[\"TOTAL INJURIES\"] > 0)]\n",
    "\n",
    "    # reset the index \n",
    "    narrow_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return narrow_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aedbb334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>STATE</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "      <th>DAMAGE_PROPERTY</th>\n",
       "      <th>DAMAGE_CROPS</th>\n",
       "      <th>SOURCE</th>\n",
       "      <th>MAGNITUDE</th>\n",
       "      <th>MAGNITUDE_TYPE</th>\n",
       "      <th>TOR_F_SCALE</th>\n",
       "      <th>TOR_LENGTH</th>\n",
       "      <th>...</th>\n",
       "      <th>BEGIN_LOCATION</th>\n",
       "      <th>BEGIN_LAT</th>\n",
       "      <th>BEGIN_LON</th>\n",
       "      <th>END_LAT</th>\n",
       "      <th>END_LON</th>\n",
       "      <th>EPISODE_ID</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>TOTAL DEATHS</th>\n",
       "      <th>TOTAL INJURIES</th>\n",
       "      <th>TOTAL DAMAGES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>25000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.9</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.58</td>\n",
       "      <td>-75.70</td>\n",
       "      <td>40.65</td>\n",
       "      <td>-75.47</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104927</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>25000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950</td>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.20</td>\n",
       "      <td>-76.12</td>\n",
       "      <td>40.27</td>\n",
       "      <td>-76.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10104931</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.00</td>\n",
       "      <td>-96.25</td>\n",
       "      <td>35.07</td>\n",
       "      <td>-96.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10099490</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>34.88</td>\n",
       "      <td>-99.28</td>\n",
       "      <td>35.00</td>\n",
       "      <td>-99.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10096220</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1950</td>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>Tornado</td>\n",
       "      <td>250000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35.08</td>\n",
       "      <td>-96.40</td>\n",
       "      <td>35.13</td>\n",
       "      <td>-96.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10096223</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR         STATE EVENT_TYPE  DAMAGE_PROPERTY  DAMAGE_CROPS  SOURCE  \\\n",
       "0  1950  PENNSYLVANIA    Tornado          25000.0           0.0     NaN   \n",
       "1  1950  PENNSYLVANIA    Tornado         250000.0           0.0     NaN   \n",
       "2  1950      OKLAHOMA    Tornado         250000.0           0.0     NaN   \n",
       "3  1950      OKLAHOMA    Tornado         250000.0           0.0     NaN   \n",
       "4  1950      OKLAHOMA    Tornado         250000.0           0.0     NaN   \n",
       "\n",
       "   MAGNITUDE  MAGNITUDE_TYPE  TOR_F_SCALE  TOR_LENGTH  ...  BEGIN_LOCATION  \\\n",
       "0        0.0             NaN          2.0        12.9  ...             NaN   \n",
       "1        0.0             NaN          3.0         4.7  ...             NaN   \n",
       "2        0.0             NaN          2.0         6.8  ...             NaN   \n",
       "3        0.0             NaN          3.0         9.4  ...             NaN   \n",
       "4        0.0             NaN          4.0         4.5  ...             NaN   \n",
       "\n",
       "   BEGIN_LAT  BEGIN_LON  END_LAT  END_LON  EPISODE_ID  EVENT_ID  TOTAL DEATHS  \\\n",
       "0      40.58     -75.70    40.65   -75.47         NaN  10104927             0   \n",
       "1      40.20     -76.12    40.27   -76.07         NaN  10104931             0   \n",
       "2      35.00     -96.25    35.07   -96.17         NaN  10099490             0   \n",
       "3      34.88     -99.28    35.00   -99.20         NaN  10096220             1   \n",
       "4      35.08     -96.40    35.13   -96.35         NaN  10096223             5   \n",
       "\n",
       "   TOTAL INJURIES  TOTAL DAMAGES  \n",
       "0               2        25000.0  \n",
       "1               1       250000.0  \n",
       "2               6       250000.0  \n",
       "3               1       250000.0  \n",
       "4              32       250000.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "narrow_cols = [\"YEAR\", \n",
    "                \"STATE\", \n",
    "                \"EVENT_TYPE\",  \n",
    "                \"INJURIES_DIRECT\", \n",
    "                \"INJURIES_INDIRECT\",\n",
    "                \"DEATHS_DIRECT\", \n",
    "                \"DEATHS_INDIRECT\",\n",
    "                \"DAMAGE_PROPERTY\",\n",
    "                \"DAMAGE_CROPS\", \n",
    "                \"SOURCE\", \n",
    "                \"MAGNITUDE\", \n",
    "                \"MAGNITUDE_TYPE\", \n",
    "                \"TOR_F_SCALE\", \n",
    "                \"TOR_LENGTH\",\n",
    "                \"TOR_WIDTH\",\n",
    "                \"TOR_OTHER_CZ_STATE\",\n",
    "                \"BEGIN_LOCATION\", \n",
    "                \"BEGIN_LAT\", \n",
    "                \"BEGIN_LON\", \n",
    "                \"END_LAT\", \n",
    "                \"END_LON\", \n",
    "                \"EPISODE_ID\", \n",
    "                \"EVENT_ID\",]\n",
    "\n",
    "cleaned_2000s_df = clean_storm_df(mergestorm_df, narrow_cols, True)\n",
    "cleaned_1950s_df = clean_storm_df(mergestorm1950_1964_df, narrow_cols, True)\n",
    "cleaned_1950s_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "484ca56d-8e9b-4b12-9136-b083278a6549",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YEAR\n",
      "2011    79091\n",
      "2008    71190\n",
      "2022    69670\n",
      "2019    67861\n",
      "2012    64503\n",
      "2010    62807\n",
      "2018    62697\n",
      "2021    61389\n",
      "2020    61279\n",
      "2013    59986\n",
      "2014    59475\n",
      "2015    57906\n",
      "2009    57398\n",
      "2017    57029\n",
      "2016    56005\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "other_2000s_df = clean_storm_df(mergestorm_df, narrow_cols, False)\n",
    "other_1950s_df = clean_storm_df(mergestorm1950_1964_df, narrow_cols, False)\n",
    "\n",
    "other_counts_1950s = other_1950s_df['YEAR'].value_counts()\n",
    "other_counts_2000s = other_2000s_df['YEAR'].value_counts()\n",
    "print(other_counts_2000s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e9a9c04-a3e4-482a-8fac-3a8f61fed683",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Storms\n",
      "   Total Elements         Mean  Median  Mode       Variance  Std Deviation\n",
      "0           22087  1472.466667  1813.0   223  670573.982222     818.885818\n",
      "   Total Elements          Mean   Median   Mode      Variance  Std Deviation\n",
      "0          948286  63219.066667  61389.0  56005  3.765093e+07     6136.03512\n"
     ]
    }
   ],
   "source": [
    "# create a summary dataframe with basic stats\n",
    "def get_summary_df(to_summarize):\n",
    "    s = to_summarize.sum()\n",
    "    mean = to_summarize.mean()\n",
    "    median = to_summarize.median()\n",
    "    mode = to_summarize.mode()\n",
    "    var = np.var(to_summarize, ddof=0)\n",
    "    dev = np.std(to_summarize, ddof=0)\n",
    "    df = pd.DataFrame({\n",
    "        \"Total Elements\": s,\n",
    "        \"Mean\": mean,\n",
    "        \"Median\": median,\n",
    "        \"Mode\": mode,\n",
    "        \"Variance\": var,\n",
    "        \"Std Deviation\": dev\n",
    "    }, index=[0])\n",
    "    return df\n",
    "\n",
    "# number of storms per year summary data\n",
    "summary_1950s = get_summary_df(other_counts_1950s)\n",
    "summary_2000s = get_summary_df(other_counts_2000s)\n",
    "print(\"All Storms\")\n",
    "print(summary_1950s)\n",
    "print(summary_2000s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "360d01c5-02ec-4cab-bfdd-a721946d30ed",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 type(s) of storm event from 1950-1964\n",
      "EVENT_TYPE\n",
      "Tornado              8575\n",
      "Thunderstorm Wind    7515\n",
      "Hail                 5997\n",
      "Name: count, dtype: int64\n",
      "\n",
      "55 type(s) of storm event from 2008-2022\n"
     ]
    }
   ],
   "source": [
    "# realize that the old data is much less extensive than new\n",
    "type_counts_1950s = other_1950s_df['EVENT_TYPE'].value_counts()\n",
    "type_counts_2000s = other_2000s_df['EVENT_TYPE'].value_counts()\n",
    "print(f\"{len(type_counts_1950s)} type(s) of storm event from 1950-1964\")\n",
    "print(type_counts_1950s)\n",
    "print()\n",
    "print(f\"{len(type_counts_2000s)} type(s) of storm event from 2008-2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0823280c-648b-4ee3-9015-2d4c8a6e41b4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tornados\n",
      "   Total Elements         Mean  Median  Mode      Variance  Std Deviation\n",
      "0            7748  1291.333333  1063.5    36  1.119362e+06    1057.998845\n",
      "   Total Elements         Mean  Median  Mode      Variance  Std Deviation\n",
      "0           20315  3385.833333  1268.5    13  1.592090e+07    3990.100643\n"
     ]
    }
   ],
   "source": [
    "tornado_counts_1950s = other_1950s_df['TOR_F_SCALE'].value_counts()\n",
    "# exclude unknown values, which pop up in the more recent data\n",
    "tornado_counts_2000s = other_2000s_df[other_2000s_df['TOR_F_SCALE'] != -1.0]['TOR_F_SCALE'].value_counts()\n",
    "\n",
    "print(\"Tornados\")\n",
    "print(get_summary_df(tornado_counts_1950s))\n",
    "print(get_summary_df(tornado_counts_2000s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b201d-845e-44d5-8842-51f3aebb2f5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
